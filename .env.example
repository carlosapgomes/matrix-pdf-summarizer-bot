# Matrix credentials
MATRIX_HOMESERVER=https://matrix.example.org
MATRIX_USER=@pdfbot:example.org
MATRIX_PASSWORD=super_secret_password
MATRIX_ROOM_ID=!yourroomid:example.org

# === Default LLM Configuration ===
DEFAULT_LLM_PROVIDER=openai          # openai, anthropic, ollama, azure, generic
DEFAULT_LLM_MODEL=gpt-5-mini         # Model identifier
DEFAULT_LLM_BASE_URL=                # Optional: Custom endpoint URL
DEFAULT_LLM_API_KEY=your_api_key     # API key for default LLM
DEFAULT_LLM_PROMPT=prompts/medical_triage.txt

# === Dual LLM Feature ===
DUAL_LLM_ENABLED=false               # Enable/disable dual processing

# === Secondary LLM Configuration (when dual enabled) ===
SECONDARY_LLM_PROVIDER=generic       # Provider for second analysis
SECONDARY_LLM_MODEL=deepseek-reasoner # Model identifier (for DeepSeek v3.2)
SECONDARY_LLM_BASE_URL=https://api.deepinfra.com/v1/openai  # DeepInfra endpoint
SECONDARY_LLM_API_KEY=               # API key for secondary LLM
SECONDARY_LLM_PROMPT=prompts/medical_triage_deepseek.txt  # DeepSeek-optimized prompt

# === LLM Parameters (apply to both) ===
LLM_TEMPERATURE=0.7                  # Optional: Response creativity
LLM_MAX_TOKENS=                      # Optional: Maximum response length

# === Backward Compatibility (deprecated but supported) ===
# OPENAI_API_KEY=                    # Falls back to DEFAULT_LLM_API_KEY
# LLM_MODEL=                         # Falls back to DEFAULT_LLM_MODEL
# LLM_BASE_URL=                      # Falls back to DEFAULT_LLM_BASE_URL
# PROMPT_FILE=                       # Falls back to DEFAULT_LLM_PROMPT

# Optional session file location
SESSION_FILE=session.json

# Job Queue Configuration
JOB_DB_PATH=jobs.db
MAX_WORKER_THREADS=3
JOB_CLEANUP_HOURS=24
MAX_JOB_RETRIES=3
COMPLETED_JOB_POLL_SECONDS=5



